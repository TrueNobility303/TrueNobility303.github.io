---
title: '高斯无向图模型'
toc: true
excerpt_separator: <!--more-->
tags:
  - 统计机器学习
---



高斯无向图模型是一种重要的概率图模型，与多元高斯分布的各种性质也密切相关。



<!--more--> 



高斯无向图将变量之间用多元高斯分布建模，此时变量之间的相关关系等价于分析其协方差矩阵。

关于概率图模型的简要介绍，可以移步至 [概率图模型](https://truenobility303.github.io/PGM/)



## Conditional Distribution of Gaussian

首先推导多元高斯分布的条件分布，


$$
\begin{align}
\begin{pmatrix}
X_1 \\
X_2
\end{pmatrix}
\sim
\mathcal{N}
\begin{pmatrix}
\mu_1 \\
\mu_2
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_{11} & \Sigma_{12} \\
\Sigma_{21} & \Sigma_{22}
\end{pmatrix}
\end{align}
$$


对其进行Schur补变换，


$$
\begin{align}
\begin{pmatrix}
I & O \\
-\Sigma_{21}\Sigma_{11}^{-1}  & I
\end{pmatrix}
\begin{pmatrix}
X_1 - \mu_1\\
X_2 - \mu_2
\end{pmatrix}
&\sim
\mathcal{N}
\begin{pmatrix}
X_1 - \mu_1 \\
(X_2-\mu_2) - \Sigma_{21}\Sigma_{11}^{-1}(X_1 - \mu_1)
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_{11} & O \\
O & \Sigma_{22-1} 
\end{pmatrix}
\\
\text{With Schur Complement }\Sigma_{22-1} &= \Sigma_{22} - \Sigma_{21} \Sigma_{11}^{-1}\Sigma_{21}  
\end{align}
$$


据此可以得到条件分布，


$$
\begin{align}
X_2 \vert X_1 &\sim \mathcal{N}(\mu_{2-1}, \Sigma_{22-1}) \\
\text{With } \mu_{2-1} &= u_2+ \Sigma_{12} \Sigma_{22}^{-1}(x_1- \mu_1)
\end{align}
$$


根据上述结论，可以得到高斯无向图模型中的独立性判定。



## Global Independent

全局的独立性只需要对协方差矩阵进行分析即可，用到了高斯分布不相关和独立等价的结论，可以用矩母函数证明，此处直接用该结论：


$$
\begin{align}
X_i \perp X_j \text{ Iff } \Sigma_{ij} = 0
\end{align}
$$


## Local Independent

局部独立性也称为Markov性质,刻画了给定其余所有变量之后两个变量的条件独立性，


$$
X_i \perp X_j, \text{Given  All } X \ne X_i,X_j   \text{ Iff } \Theta_{ij} = 0,\text{With } \Theta = \Sigma^{-1}
$$


其中，矩阵$\Theta$为协方差矩阵$\Sigma$的逆矩阵，也被称为精度矩阵或浓度矩阵（Precision Matrix，Concentration Matrix）。

证明用到上述两个矩阵的关系，


$$
\begin{align}
\begin{pmatrix}
\Theta_{11} & \Theta_{12} \\
\Theta_{21} & \Theta_{22}
\end{pmatrix}
= 
\begin{pmatrix}
\Sigma_{11} & \Sigma_{12} \\
\Sigma_{21} & \Sigma_{22}
\end{pmatrix}^{-1}
\end{align}
$$


利用上述Schur补中的合同变换，可以得到，


$$
\begin{align}
\Theta_{11}^{-1} &= \Sigma_{11-2} \\
\Theta_{22}^{-1} &= \Sigma_{22-1} 
\end{align}
$$


而此时关于$i,j$的条件协方差矩阵为$2 \times 2$矩阵，可以算出其逆矩阵并且得到结论，




$$
X_i \perp X_j, \text{Given  All } X \ne X_i,X_j   \text{ Iff } \Theta_{ij} = 0
$$




## Conditional Expectation

如果已知除了$X_i$以外其他所有变量的分布，可以对$X_i$进行预测，此时可以使用条件分布的均值进行预测。


$$
\begin{align}
\begin{pmatrix}
\Theta_{11} & \Theta_{12} \\
\Theta_{21} & \Theta_{22}
\end{pmatrix}
\begin{pmatrix}
\Sigma_{11} & \Sigma_{12} \\
\Sigma_{21} & \Sigma_{22}
\end{pmatrix} 
= I
\end{align}
$$


应用矩阵分块运算，


$$
\begin{align}
\Theta_{11} \Sigma_{11} + \Theta_{12} \Sigma_{21}  &= I \\
\Theta_{11} \Sigma_{12} + \Theta_{12} \Sigma_{22}  &= O \\
\Theta_{21} \Sigma_{11} + \Theta_{22} \Sigma_{21}  &= O \\
\Theta_{21} \Sigma_{12} + \Theta_{22} \Sigma_{22}  &= I \\
\end{align}
$$


提取我们关心的部分，


$$
\Sigma_{21} \Sigma_{11}^{-1} = - \Theta_{22}^{-1} \Theta_{21}
$$


而对于$X_i$的条件分布的上述部分，有明显的含义，代入可以得到，


$$
\begin{align}
E[X_i \vert X \ne X_i]  &= u_i+ \Sigma_{12} \Sigma_{22}^{-1}(X- \mu) \\
&= \mu_i - \Theta_{22}^{-1} \Theta_{21}(X- \mu) \\
&= \mu_i - \frac{\sum_k \theta_{ik} (X_k - \mu_k)}{\theta_{ii}}
\end{align}
$$


也即只需要关注$\theta_{ik}$中的非零部分，对其进行线性组合即可，由于在现实数据中该矩阵通常为稀疏矩阵，上述性质在实际问题的计算中非常有用。