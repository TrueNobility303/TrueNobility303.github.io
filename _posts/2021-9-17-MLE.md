---
title: '极大似然估计的性质'
toc: true
excerpt_separator: <!--more-->
tags:
  - 统计
---



总结关于极大似然估计（Maximum Likelihood Estimate，MLE）的相关性质证明，包括同变性、一致性、渐进正态性。

<!--more-->

一些证明主要参考了 [极大似然估计](http://www.doc88.com/p-87319681759.html)

## 同变性

**若$MLE(\theta) = \hat{\theta},\tau=g(\theta)$,则$MLE(\tau)=g(\hat{\theta})$**

同变性的证明是显然的，因为$\tau$和$\theta$有一一对应的关系，$\hat{\theta}$使得似然函数取得最大值，则当$\tau=g(\hat{\theta})$的时候，$\hat{\tau}$也使得似然函数取得最大值。



## 一致性

$\hat{\theta} \rightarrow \tilde{\theta}$, 其中$\hat{\theta}$为极大似然估计的参数，$\tilde{\theta}$是模型的真实参数。

一致性的含义是，极大似然估计收敛于模型的真实参数。

证明：$\hat{\theta}$为使得似然函数的经验分布函数最大，根据熟知的结论，经验分布函数收敛于分布函数。

上述结论的证明此处暂略，但说明证明方法，实际上为Dvoretzky-Kiefer-Wolfowitz(DKW)不等式，本质上是Hoeffding不等式的经验分布函数版本。

对于该不等式的证明，首先需要知道经验分布函数的定义，以及其期望和方差满足，$E[F_n(x)]  = F(x), Var[F_n(x)] = \frac{1}{n}F(x)(1-F(x))$,参考[知乎回答: 经验分布函数的期望和方差](https://www.zhihu.com/question/374467368?sort=created). 本质上利用了经验分布函数、示性函数的期望的关系。其次是Hoeffding不等式, 该不等式通常用于机器学习中证明泛化误差上界，可以参见 [Hoeffding不等式]((https://blog.csdn.net/u010510549/article/details/47839241))

而且我们知道，$\hat{\theta}$是使得似然函数的经验分布函数最大的估计量。

再者，$\tilde{\theta}$ 是使得似然函数最大的估计量，结论具有直观的意义，也可以严谨证明:

对于任意$\theta$,$L(\theta) - L(\tilde {\theta}) = E_{\tilde \theta}[\log \frac{p(x \vert \theta)}{p(x \vert \tilde \theta)} ] \le \int (\frac{p(x \vert \theta)}{p(x \vert \tilde \theta)}-1) p(x \vert \tilde \theta) dx =0 $

也即$L(\theta) - L(\tilde {\theta}) \le 0$ ，得证。



总结上述证明的几个部分，得到一致性的证明。

* 经验分布函数收敛于分布函数
* $\hat{\theta}$为使得似然函数的经验分布函数最大的点
* $\tilde{\theta}$ 是使得似然函数最大的点

因此可以直观知道，极大似然估计收敛于模型的真实参数，得证。



## 渐进正态性

假设模型的真实参数为$\theta$，而MLE给出的参数估计为$\hat \theta$,我们有

$\sqrt{n} (\hat \theta - \theta) \rightarrow N(0,1/I)$ .其中$I$为Fisher信息矩阵，其定义为$I = Var[s],s=\nabla\log p(x \vert \theta)$ 

简单推导可以得到Fisher信息矩阵的性质，可以参见 [自然梯度与KFAC](https://truenobility303.github.io/KFAC/) 中的理论推导部分。

$E[s] = 0, E[\nabla s] = -I, Var[s] = E[s^2] = I$

根据上述的一致性结论，对于经验得分函数$\hat s$, 可以在$\hat \theta$附近对其进行展开，$\nabla (\hat \theta) - \nabla(\theta) = \nabla^2(\theta)(\hat \theta - \theta)$

又根据MLE的定义，$\nabla (\hat \theta) = 0$，并且移项可以得到，

$\sqrt{n} (\hat \theta - \theta) = -\frac{\nabla(\theta) / \sqrt{n}}{\nabla^2(\theta) /n}= -\frac{\hat s / \sqrt{n}}{\nabla \hat s / n}$

对于上述的$\hat{s}$.根据大数定理，关于大数定理的特征函数版本证明，可以参见[常用分布与假设检验](https://truenobility303.github.io/Hypothesis-Testing/)

$\hat s / \sqrt{n} \rightarrow N(E[s],Var[s]) = N(0,I)$

$\nabla \hat s / n = E[\nabla s] = -I$ 

因此，可以得到，MLE的估计的确收敛于一个方差与Fisher信息矩阵相关的正态分布，$\sqrt{n} (\hat \theta - \theta) \rightarrow N(0,1/I)$

