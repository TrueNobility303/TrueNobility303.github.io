---
title: '时间序列'
toc: true
excerpt_separator: <!--more-->
tags:
  - 时间序列
---



主要包括ARIMA的模型构建、识别、预测、估计等时间序列分析的核心内容。对于一般平稳时间序列的预测，从希尔伯特空间投影的角度给出Durbin-Levinson 算法的证明。对于一般的ARIMA模型，给出其长程预测的极限性质和基于递推公式的预测算法。

<!--more-->

$$
\begin{pmatrix}
a  & b \\
c  & d \\
\end{pmatrix}
$$


ARIMA，其实是 Auto Regression Integrated Moving Average.

可以看作几个模型的复合：

* AR（Auto Regression），自回归模型
* MA（Moving Average），移动平均模型
* ARMA（AR+MA），移动平均自回归模型
* ARIMA（ARMA+I），加入积分的 ARMA模型，用于处理非平稳时间序列



## Stationary

对于时间序列分析的任务，本质上需要寻找时间序列的时间不变性质，而平稳性就是对该性质的刻画。主要分为：

* Strict Stationary：强平稳（严平稳）
* Weak Stationary：弱平稳（宽平稳）

**Stict Stationary**

强平稳指的是，时间序列的分布关于时间平移不变： 

$$
(t_1,t_2,...,t_n) \sim (t_{1+h},t_{2+h},...,t_{n+h})
$$

**Weak Statinary**

弱平稳指的是，时间序列的期望和协方差关于时间平移不变。

$$
\mu(t) = E[X_t] =Const \\
\gamma(s,t) =  Cov[X_s,X_t] = \gamma(h), h = \vert t -s \vert
$$

也即，时间序列的均值为与时间无关的常数，而协方差只依赖于时间差。

由于，对于均值$\mu(t) \ne 0$ 的情况，可以令$Y_t = X_t - \mu_t$, 从而化归为均值为0的情况，因此下面仅考虑均值为0的情况。

---

由于强平稳刻画的是分布的性质，而弱平稳刻画的是一阶矩和二阶矩的性质。

我们通常假设一阶矩和二阶矩存在，此时强平稳条件可以推出弱平稳条件。

平稳性实际上是随机过程的性质，考虑几大常见的随机过程的平稳性：

* 时齐泊松过程，平稳，详见 [泊松过程](https://truenobility303.github.io/Poisson/)
* 马尔可夫链，其平稳分布和极限分布存在联系，详见 [马尔可夫链](https://truenobility303.github.io/Markov-Chain/)
* 布朗运动，非平稳，从其协方差$\gamma(s,t) = \min(s,t)$可以看出，详见 [布朗运动](https://truenobility303.github.io/Brown-Motion/)



## Auto Covariance Function(ACF)

在下面的分析中，我们都首先假设所分析的时间序列是平稳的，且一阶矩和二阶矩都存在。

由于我们不考虑均值，上述定义的自协相关函数，是平稳时间序列的核心特征，下面列出其重要性质：

* $\gamma(0) = Var[X_t]$，根据定义可得
* $ \vert \gamma(h) \vert \le \gamma(0)$，本质上为Cauthy不等式，据此可以定义，$\rho(h) = \frac{\gamma(h)}{\gamma(0)}$ 
* $\gamma(h) = \gamma(-h)$



## AR(I)

自回归模型的本质是用前一段时间，回归当前的时间。

定义BackShift算子$B$,满足：

$$
B X_t = X_{t-1}
$$

易验证，算子$B$是一个满足交换律、结合律、分配律的线性算子，定义其$p$阶多项式$\phi(B)$,则$AR(p)$模型可以表示为，

$$
\phi_p(B) = W_t
$$

其中，$W_t \sim (0,\sigma^2)$为$i.i.d$的白噪声序列。

---

本节主要考虑AR(I)模型，以该模型为例说明AR模型的一些特点，便于后续的推广。

$$
X_t = \phi X_{t-1} + W_t,W_t \sim(0,\sigma^2)
$$

时间序列中一个重要的性质是因果性（Casualty），也即当前时间的状态可以用过去时间的状态来表示。

对于AR(I)模型，其重要的性质是：

* 若$\vert \phi \vert <1$， 存在唯一平稳解，且满足因果性
* 若$\vert \phi \vert =1$，不存在平稳解
* 若$\vert \phi \vert <1$， 存在唯一平稳解，但不满足因果性，但存在某种满足因果性的对偶序列



**Property of AR(I)**

证明AR(I)模型的性质，对于整类AR模型的理解至关重要。



1.若$\vert \phi \vert =1$，也即$X_t =  \sum_{j=0}^{\infty} W_{t-j}$, 也即简单随机游动，可以参见  [布朗运动](https://truenobility303.github.io/Brown-Motion/)

其协方差 $\gamma(s,t )  = \min(s,t)$不仅仅依赖于时间差$h$，因此不满足平稳性。



2.若$\vert \phi \vert <1$， 递推可以得到，$X_t = \lim_{n \rightarrow \infty} \phi^n X_{t-n} + \sum_{j=0}^{\infty} \phi^j W_{t-j}$

$\lim_{n \rightarrow \infty} E[(\phi^n X_{t-n})^2] =  \lim_{n \rightarrow \infty} \phi^{2n} E[ X_{t-n}^2] =0$ , 根据$X_t$二阶矩有限的性质。

也即在均方意义下收敛，$X_t \rightarrow \sum_{j=0}^{\infty} \phi^j W_{t-j}$

均方意义收敛是很强的收敛条件，可以参见 [随机变量的收敛](https://truenobility303.github.io/Coverage/)

下面证明，这是一个平稳解。显然，$E[X_t] = 0$。对于自相关函数，$\gamma(h) = \frac{\phi^h}{ 1-\phi^2} \sigma^2 ,\rho(h) = \frac{\gamma(h)}{\gamma(0)} =   \phi^h \sigma^2 $
$\gamma(h), \rho(h)$都为仅依赖于时间差$h$的量，满足平稳性。



3.若$\vert \phi \vert >1$， 不应该像$\vert \phi \vert <1$的情况下向过去递推，而应该像未来递推。

得到，$X_t = \lim_{n \rightarrow \infty} \phi^{-n} X_{t+n} + \sum_{j=1}^{\infty}  \phi^{-j} W_{t+j}$

从而，在均方意义下，$X_t \rightarrow \sum_{j=1}^{\infty}  \phi^{-j} W_{t+j}$，尽管得到了一个平稳解，但由于$X_t$需要依赖于未来的值，不满足因果性，得到的平稳解也无意义。

但考虑另外一个时间序列过程，满足，$Y_t = \phi^{-1} Y_{t-1} + W_t,W_t \sim (0,\phi^{-2} \sigma^2)$ 

可以验证，$\rho_X(h) = \rho_Y(h) = \phi^{-2} \phi^{-h} \sigma^2$

我们称像这样均值和协方差都相等的时间序列为，**随机等价**。

因此对于$\vert \phi \vert >1$的情况，总可以定义另外一个$\vert \phi \vert <1$ 的时间序列，使得这两个时间序列随机等价，因此我们考虑的研究范围仅仅限定在$\vert \phi \vert <1$。



## MA(I)

移动平均模型的思路与AR模型相反，将当前的值看作之前一段时间的残差的线性组合。

$$
X_t = \theta_q(B)W_t
$$

相较于AR模型，MA模型是更为简单的，易于验证MA模型一定满足平稳性。

类似于对AR模型的理解，我们首先从最简单的MA(I)模型入手。

$$
X_t =  W_t + \theta W_{t-1},W_t \sim(0,\sigma^2)
$$

计算其自相关函数，可以得到，$\rho(1) = \frac{\theta}{1+\theta^2} \sigma^2$

而对于相距较远的其他位置，由于没有交叠，$\rho(h) = 0,h >1$

定义另外一个时间序列，$Y_t = W_t + \theta^{-1} W_{t-1},W_t \sim(0,\theta^2\sigma^2) $,这两个时间序列也是随机等价的。

为了规定MA模型的唯一性，对于MA(I)限定，$\vert \theta \vert <1$



## ARMA

ARMA模型也即融合了AR和MA模型，同样使用算子$B$可以表示为:

$$
\phi_p(B) X_t = \theta_q(B) W_t
$$

ARMA模型需要满足一些限制：

* 参数无冗余，也即$\phi(B),\theta(B)$之间无公因式
* 因果性，来自于AR模型仅依赖于过去的保证，需要满足，$\phi(z)$在复数域的所有根都在单元圆外。
* 不可逆性，来自于MA模型的唯一性保证，需要满足，$\theta(z)$在复数域的所有根都在单元圆外

上述对于因果性和不可逆性的约束来自于对上两节对于AR(I)和MA(I)模型的性质的讨论的推广，但其严格的证明需要用到复变函数的知识，此处不加证明地给出结论。

对于满足上述约束的ARMA模型，可以将$X_t$用过去的$W_t$表示，或者相反地将$W_t$用过去的$X_t$表示。

$$
X_t = \sum_{j=0}^{\infty} \psi_j W_{t-j} \\
W_t = \sum_{j=0}^{\infty} \pi_j X_{t-j}
$$

由此，我们定义得到几个模型，$p,q$表示模型的多项式的阶数：

* $AR(p)$
* $MA(q)$
* $ARMA(p,q)$

## Partial Auto Covariance Function(PACF)

在模型识别中，我们需要判断给定的时间序列满足AR、MA、ARMA模型的性质，并且确定其阶数。

此时不仅需要观察序列的自相关函数，还需要观察序列的偏自相关函数。

---

首先考虑自相关函数, 对于$MA(q)$模型,由于$X_t$仅依赖于前$q$个时间点的$W_t$，因此在$MA(q)$模型中，

$$
\text{acf(h)} = 0, h > q
$$

也即$MA(q)$模型的自相关函数在$q$之后截断，因此可以通过绘制其自相关函数判断其阶数。

而对于$AR(p)$模型，考虑其自相关函数，根据$\phi(B)X_t = W_t$, 对于$h \ge1$的情况，

$$
\begin{align}
X_t &= \phi_1X_{t-1} + \phi_2X_{t-2} +...+\phi_pX_{t-p} +W_t \\
E[X_t X_{t-h}] &=  \phi_1 E[X_{t-1}X_{t-h}] + \phi_2E[X_{t-2}X_{t-h}] +...+\phi_pE[X_{t-p}X_{t-h}] +E[W_t X_{t-h}] \\
\gamma(h) &= \phi_1\gamma(h-1)+ \phi_2 \gamma(h-2) +...+\phi_p \gamma(h-p) \\
\end{align}
$$

而对于$h=0$的情况，类似，但需要多考虑白噪声序列$W_t$的方差$\sigma^2$,并利用$E[W_tX_t] = E[W_t^2] = \sigma^2$：

$$
\gamma(0) = \phi_1\gamma(1)+ \phi_2 \gamma(2) +...+\phi_p \gamma(p) + \sigma^2
$$

该差分方程也称为Yule-Walker方程，解上述差分方程可以得到自相关函数$\gamma(h)$,或$\text{acf}(h)$：

设特征方程，$\phi(z) = 0$的根为$z_1,z_2,...z_p$，根据因果性，$\vert z \vert >1$, 根据差分方程的通解：

$$
\gamma(h) = z_1^{-n} P_1(n) + z_2^{-n} P_2(n) +...+ z_p^{-n} P_3(n)
$$

其中，$P(n)$为关于$n$的多项式函数，可以发现，$\gamma(h)$呈指数衰减趋近于0，但其永不截断（Tail Off）

因此，通过自相关函数$\text{acf}$不能够判断$AR(p)$模型的阶数，需要一种新的指标，也即偏自相关函数。

---

偏自相关函数，Partial Auto Covariance Function(PACF)，定义为给定$X_t,X_{t+h}$的中间量$X_{t+1},X_{t+2},....X_{t+h-1}$的前提下，对$X_t,X_{x+h}$进行最优线性预测的误差的残差的相关系数。

$$
\text{pacf}(h) = \text{Corr}(X_t - \hat X_t,X_{t+h}- \hat X_{t+h})
$$

最优线性预测，可以看作对随机变量所张成的希尔伯特空间内的一组基的投影，投影后的部分就是可以被这组基线性表示的部分，而残差则是不能被这组基线性表示的部分。

对于$AR(p)$模型，可以发现偏自相关系数在$p$个时间点之后截断：

$$
\text{pacf}(h) = 0, h>p
$$

证明用到了最优线性预测与投影的性质，当$h >p$时，由于$X_{t+h}$一定可以表示为前$p$个时间点的观测值的线性组合，因此$X_{t+h} -\hat X_{t+h} = W_{t+h}$, 同时根据因果性，$W_t \perp (X_t,X_{t+1},...X_{t+h})$,因此有，$\text{pacf}(h) = 0$

而对于$MA(q)$模型，将$W_t$表示为$ X_t$的组合， 显然需要用到无限维阶数，$W_t = \phi(B) X_t$，相当于一个阶数为$\infty$的$AR(\infty)$过程，因此其偏自相关系数一般永不截断。

### Model Recognition

而对于ARMA模型，由于其混合了AR和MA两个模型，已知其自相关函数和偏自相关函数都永不截断，模型识别整理如下表：

| Model     | ACF                 | PACF                |
| --------- | ------------------- | ------------------- |
| AR(p)     | Tail Off            | Cut Off After Lag p |
| MA(q)     | Cut Off After Lag q | Tail Off            |
| ARMA(p,q) | Tail Off            | Tail Off            |

## ARIMA

ARMA模型针对的是平稳时间序列模型，而ARIMA通过引入积分的方法，将非平稳的时间序列转化为平稳时间序列。

考虑时间序列，$X_t = \mu_t + Y_t$, 其中$Y_t$为平稳时间序列，$\mu_t$反映了$X_t$的整体趋势。

ARIMA的核心是利用差分算子，进行去趋势化，差分算子$D =1-B$满足，$DX_t =(1-B)X_t =  X_t - X_{t-1}$

已知，对于平稳的时间序列，进行差分之后,，仍然为平稳的时间序列。

而对于关于时间$t$的$d$阶多项式，进行$d$阶差分之后，将变为平稳时间序列。

因此，假设$\mu_t$为关于$t$的$d$阶多项式函数，其进行$d$阶差分之后，$X_t$为平稳时间序列，可以使用ARMA模型。

综上，$ARIMA(p,d,q)$模型可以表示为：

$$
\phi_p(B) (1-B)^d X_t = \theta_q(B) W_t
$$

阶数$p,q$的确定可以通过观察自相关函数和偏自相关函数的截断性质，而阶数$d$的确定依赖于对序列平稳性的考察，通常尝试对序列作用差分算子$D$直到满足或近似满足平稳性。



## Estimation

识别模型之后，通常需要根据数据确定模型的参数，对于一般化的$ARMA(p,q)$模型，需要估计的参数包括多项式$\phi(z),\theta(z)$的系数，以及白噪声序列$W_t$的方差$\sigma^2$, 也即：$\phi_1,\phi_2,...,\phi_p, \theta_1,\theta_2,...\theta_q,\sigma^2$

对于ARMA模型的估计主要有以下几种方法：

* 矩估计
* 最大似然估计
* 最小二乘估计

### Method of Momentum

对于AR模型，可以采用矩估计，其核心是根据Yule-Walker方程，该方程用于求解自相关函数。

$$
\begin{align}
\gamma(h) &= \phi_1\gamma(h-1)+ \phi_2 \gamma(h-2) +...+\phi_p \gamma(h-p),h \ge 1\\
\gamma(h) &= \phi_1\gamma(1)+ \phi_2 \gamma(2) +...+\phi_p \gamma(p) + \sigma^2,h=0
\end{align}
$$

使用样本自相关函数$\hat \gamma(h)$替代上述方程中的$\gamma(h)$，解线性方程组就可以得到对参数的估计。

### MLE and LSE

对于MA和ARMA模型，矩估计将非常复杂，通常采用其他方式，如：最大似然估计（MLE，Maximum Likelihood Estimate），或最小二乘估计（LSE，Least Square Estimate）。

关于最大似然估计的性质，可以参见  [极大似然估计的性质](https://truenobility303.github.io/MLE/)

由于$W_t$服从正态分布，因此对于ARMA模型，最大似然估计和最小二乘估计具有内在联系。

最大似然估计和最小二乘估计本质上都为一个优化问题，但由于在多数ARMA模型中，该优化问题的求解非常复杂，通常需要借助于数值手段。

同时，如果给定了前几个时刻$X_t,W_t$的取值，似然函数或者残差平方和可能会变的计算简洁，因此也可以在给定前几个时刻的条件下，求解条件最大似然估计或者条件最小二乘估计。、

## Forecasting

### Durbin-Levinson Algorithm

本节先从一般的平稳时间序列出发，探索其预测算法，并且主要聚焦于Durbin-Levinson算法。

已知部分观测值$X_1,X_2,...,X_n$，用其预测$X_{n+1}$时刻的取值，并且将$X_{n+1}$写成所有观测值的线性组合，$\hat X_{n+1} = \tilde \phi_1 X_1 + \tilde \phi_2 X_{2}+...+\tilde \phi_n X_n$

基于递推的思想，首先假设已知用观测值$X_2,...,X_n$预测$X_{n+1}$的参数，$\hat X_{n+1} = \phi_2X_2+...+\phi_n X_n$

记空间$(X_2,...X_n)$的投影矩阵为$P$，则增加了观测量$X_1$之后，本质上增加了一组基$e = X_1 - PX_1$

记$\alpha = \frac{ \langle X_{n+1}, X_1 - PX_1\rangle}{\Vert X_1 - PX_1 \Vert_2} = \frac{ \langle X_{n+1}, X_1 - PX_1\rangle}{\langle X_1,X_1 - PX_1 \rangle}$,则有：

$$
\hat X_{n+1} =  PX_{n+1} + \alpha (X_1 - PX_1) \\
$$

根据递推前提，

$$
PX_{n+1} =  \phi_2X_2+...+\phi_n X_n \\
$$

根据平稳性质，$(X_1,X_2,...,X_n),(X_n,...,X_2,X_1)$具有相同的协方差，其投影也具有相同的系数，

$$
e = X_1 - PX_1 = X_1 - (\phi_2 X_n+ ...+\phi_n X_2)
$$

据此得到了，

$$
\hat X_{n+1} = \alpha X_1 + (\phi_2 - \alpha \phi_n)X_2+(\phi_3 - \alpha \phi_{n-1} )X_3 + ...+(\phi_n - \alpha \phi_2)X_n
$$

下面只需要求解$ \alpha$,根据自相关函数，有：

$$
\alpha =  \frac{ \langle X_{n+1}, X_1 - PX_1\rangle}{\langle X_1,X_1 - PX_1 \rangle} = \frac{\gamma(n) - (\phi_2\gamma(1)+...+\phi_n \gamma(n-1) )}{\gamma(0)-(\phi_2 \gamma(n-1))+...+\phi_n \gamma(2)}
$$

同时，根据平稳性质，$(X_1,X_2,...,X_n),(X_n,...,X_2,X_1)$不仅投影也具有相同的系数，其投影的残差模长相等，

$$
\Vert X_{n+1} - PX_{n+1} \Vert_2^2 = \Vert X_1 - P X_1 \Vert_2^2
$$

最后计算投影误差的递推式，假定已知上一步的误差$\epsilon^2 = \Vert X_{n+1} - PX_{n+1} \Vert_2^2$,递推新的误差，

$$
\begin{align}
\tilde \epsilon^2 &= \Vert  X_{n+1} - PX_{n+1} - \alpha (X_1 - PX_1)\Vert_2^2 \\
&=\Vert X_{n+1} - PX_{n+1} \Vert_2^2 + \alpha^2 \Vert X_1 - PX_1 \Vert_2^2 - 2 \alpha \langle X_{n+1} - PX_{n+1}, X_1- PX_1\rangle \\
&= (1-\alpha^2) \epsilon^2
\end{align}
$$

因此，Durbin-Levinson算法的递推公式总结为：

$$
\begin{align}
\hat X_{n+1} &= \alpha X_1 + (\phi_2 - \alpha \phi_n)X_2+(\phi_3 - \alpha \phi_{n-1} )X_3 + ...+(\phi_n - \alpha \phi_2)X_n \\
\alpha &=  \frac{\gamma(n) - (\phi_2\gamma(1)+...+\phi_n \gamma(n-1) )}{\gamma(0)-(\phi_2 \gamma(n-1))+...+\phi_n \gamma(2)} \\
\tilde \epsilon^2 &= (1-\alpha^2) \epsilon^2 \\
\end{align}
$$

对于算法中的参数$\alpha$，本质上也是偏自相关系数：

$$
\begin{align}
\alpha &= \frac{ \langle X_{n+1}, X_1 - PX_1\rangle}{\langle X_1,X_1 - PX_1 \rangle} \\
&= \frac{ \langle X_{n+1} -P X_{n+1}, X_1 - PX_1\rangle}{\langle X_1-PX_1,X_1 - PX_1 \rangle} \\
&= \frac{ \langle X_{n+1} -P X_{n+1}, X_1 - PX_1\rangle}{\Vert X_1 -PX_1 \Vert_2 \Vert X_{n+1} - P X_{n+1} \Vert_2} \\
&= \text{pacf}(n)
\end{align}
$$

### Long Range Forecasting for ARMA

上面的Durbin-Levinson算法适用于一般的平稳时间序列，而对于ARMA模型，可以采用其他也许更优的方法。

本节考虑对于ARMA模型的长程预测，并且证明其预测值会收敛于均值，而预测误差收敛于方差。

首先根据因果性，将$X_t$表示为过去的一系列$W_t$的线性组合：

$$
X_t = \sum_{j=0}^{\infty} \psi_j W_{t-j} \\
$$

由于$W_t$服从正态分布，因此$ X_t$也服从正态分布。

而对于正态分布，最优线性预测等价于条件期望，也即在观测到$X_{t-(m+1)},X_{t-(m+2)},...X_{t-(m+n)}$的前提下，

$$
\hat X_t = E[X_t \vert X_{t-(m+1)},X_{t-(m+2)},...,X_{t-(n+m)}] \\
\hat W_t =  E[W_t \vert X_{t-(m+1)},X_{t-(m+2)},...,X_{t-(n+m)}]
$$

对等式两边同时取条件期望，

$$
\hat X_t = \sum_{j=m+1}^{n+m} \psi_{j} W_{t-j}
$$

当$m \rightarrow \infty$时，由于$E[\hat X_t^2] = \sigma^2 \sum_{j=m+1}^{\infty} \psi_j^2  \rightarrow 0$

上述为均值为0的情况，对于均值为$\mu$的情况，ARMA的长程预测将收敛于均值$\mu$.

而对于预测误差，$\epsilon = \sum_{j=0}^{m} \psi_j W_{t-j}$

当$m \rightarrow \infty$时，$\epsilon^2 =\sigma^2\sum_{j=0}^{\infty} \psi_j^2 = \gamma(0)$,也即ARMA的长程预测将收敛于方差$\gamma(0)$.



### Truncated Forecasting for ARMA

对于AR模型，由于$X_t$仅仅依赖于前$p$个时间点的观测值，其预测是显然的，只需要自回归系数即可。

但对于MA、ARAM模型，$X_t$依赖于历史无限个时间点的观测值，但其预测可以借鉴自AR模型的预测，

上面我们根据ARMA模型的因果性，给出了对于ARMA模型的长程预测的极限性质。

下面我们根据ARMA模型的可逆性，给出其短程预测。

$$
W_t = \sum_{j=0}^{\infty} \pi_j X_{t-j} = X_t+ \sum_{j=0}^{\infty} \pi_j X_{t-j}
$$

对上式两边同时取条件期望，并且依据$\hat W_t = 0$,

$$
\hat X_t = -\sum_{j=1}^{\infty} \pi_j \hat X_{t-j} = -\sum_{j=1}^{m} \pi_j \hat X_{t-j} - \sum_{j=m+1}^{\infty} \pi_j X_{t-j}
$$

在观测到$X_{t-(m+1)},X_{t-(m+2)},...X_{t-(m+n)}$的前提下，并且假设$n \rightarrow \infty$:

$$
\hat X_t = -\sum_{j=1}^{m} \pi_j \hat X_{t-j} - \sum_{j=m+1}^{m+n} \pi_j X_{t-j}
$$

上式假定$n$足够大，近似获得了历史无限个时间点的观测值。在实际中仅能取有限的$n$，因此称为带截断的预测。

根据上面给出的递推关系式，可以递推地给出对$\hat X_t$的预测结果。

